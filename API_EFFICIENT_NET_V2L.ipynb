{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KypwgpKoJgj9",
        "outputId": "bda923b8-54f1-4d72-e7b5-ab6a052eaad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "  \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysDX9WUH5zLL"
      },
      "source": [
        "## **Importing necessary packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04LhFxNiE-Hs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPool2D,MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# from tf.keras.applications import VGG16\n",
        "from keras import models, layers, optimizers\n",
        "import matplotlib.image as mpimg\n",
        "import math\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3cz94Dk58zW"
      },
      "source": [
        "## **2. Load the Image Training and Validation Datasets**\n",
        "\n",
        "### i. Get the Image Dataset Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZq0HIm3KGea"
      },
      "outputs": [],
      "source": [
        "train_dataset_path = '/content/drive/MyDrive/FYP/train'\n",
        "validation_dataset_path = '/content/drive/MyDrive/FYP/val'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTaERaUF6RjN"
      },
      "source": [
        "### ii. Load Image Datasets and Apply Augmentations\n",
        "Since the images present in the datasets are 150x150px in size, the image height and width are taken as 150, 150 respectively. The batch size value can be changed if required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjjPlgoKKTf9"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 176\n",
        "IMG_HEIGHT = 176\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPuTl-ly60CA"
      },
      "source": [
        "Loading the training dataset and applying augmentations on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tDns1iiKY9R",
        "outputId": "02e0f30d-08e5-420a-94c7-ef5cf69e568e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
        "                                  zoom_range=0.2,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  fill_mode='nearest')\n",
        "train_generator = train_datagen.flow_from_directory(train_dataset_path,\n",
        "                                                   target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "                                                   batch_size=BATCH_SIZE,\n",
        "                                                   class_mode='categorical',\n",
        "                                                   shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iWWf7F3673Y"
      },
      "source": [
        "Loading the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tShoY7dOKeB2",
        "outputId": "f2c0dfae-3d6a-453f-9d10-0de3e57abd99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1505 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "validation_generator = validation_datagen.flow_from_directory(validation_dataset_path,\n",
        "                                                             target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "                                                             batch_size=BATCH_SIZE,\n",
        "                                                             class_mode='categorical',\n",
        "                                                             shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihl6zpK17TSm"
      },
      "source": [
        "## **4. Training a Xception Model**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### i. Create a Xception Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPZoc6NrKpZr",
        "outputId": "4d498602-ff5e-4836-d1c0-4d367ac3de0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-m_notop.h5\n",
            "214201816/214201816 [==============================] - 7s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = tf.keras.applications.EfficientNetV2L(\n",
        "                     include_top=False,\n",
        "                     weights='imagenet',\n",
        "                     input_shape=(150,150,3),\n",
        "                     include_preprocessing=True\n",
        "                     )\n",
        "\n",
        "base_model.trainable=True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "        base_model,  \n",
        "        tf.keras.layers.BatchNormalization(renorm=True),\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(2, activation='softmax')\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "Dbf21ZOngPXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPk1d6nk7sKP"
      },
      "source": [
        "### ii. Defining Callbacks\n",
        "A callback is an object that can perform actions at various stages of training (e.g. at the start or end of an epoch, before or after a single batch, etc)\n",
        "\n",
        "a. Reduce Learning Rate on Plateau\n",
        "Is used to reduce the learning rate when a metric has stopped improving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROL_3PYfK1lb"
      },
      "outputs": [],
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5)\n",
        "# early = tf.keras.callbacks.EarlyStopping( patience=10,\n",
        "#                                           min_delta=0.001,\n",
        "#                                           restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmTDNuIN7zYJ"
      },
      "source": [
        "### iii. Defining the Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3R9Igw-hK5um"
      },
      "outputs": [],
      "source": [
        "optimizer= tf.optimizers.Adamax(learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDQb9yIw-TXl"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiOYiuJE77Sf"
      },
      "source": [
        "### iv. Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_myypXEtJXs"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow_addons\n",
        "\n",
        "METRICS = [\n",
        "      # tf.keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
        "      # tf.keras.metrics.Accuracy(name='accuracy'),\n",
        "      tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),  \n",
        "      tf.keras.metrics.AUC(name='auc'),\n",
        "      # tf.keras.metrics.F1Score(name='F1'),\n",
        "      #tfa.metrics.F1Score(num_classes= 4,name=\"f1_Score\")\n",
        "\n",
        "    \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xawavRLK8Nd"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=METRICS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1omQqtET79qP"
      },
      "source": [
        "### v. Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "Guj_L2QRK_7-",
        "outputId": "f1ae7698-46fe-4066-a683-9f6b88494eb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ffa0f2b482e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(train_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1445\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1446\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=15,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=2,\n",
        "                    epochs=30,verbose = 2,\n",
        "                    callbacks=[reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n__ZtKVXZZlB"
      },
      "outputs": [],
      "source": [
        "model.save('Efficient_net_v2l_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras_file='alzheimer_model.h5'\n",
        "tf.keras.models.save_model(model,keras_file)"
      ],
      "metadata": {
        "id": "JT0UmOoBy4gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {value: key for key, value in train_generator.class_indices.items()}\n",
        "\n",
        "print(\"Label Mappings for classes present in the training and validation datasets\\n\")\n",
        "for key, value in labels.items():\n",
        "    print(f\"{key} : {value}\")"
      ],
      "metadata": {
        "id": "qkbxbPR7ybY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create new file test.py and run this file\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "#load saved model\n",
        "model = load_model('alzheimer_model.h5') \n",
        "img_path =\"/content/drive/MyDrive/care buddy/archive/Alzheimer_s Dataset/train/MildDemented/mildDem10.jpg\"\n",
        "img = image.load_img(img_path, target_size=(176, 176))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "preds=model.predict(x)\n",
        "# create a list containing the class labels\n",
        "class_labels = ['NonDemented','VeryMildDemented','MildDemented','ModerateDemented']\n",
        "# find the index of the class with maximum score\n",
        "pred = np.argmax(preds, axis=-1)\n",
        "# print the label of the class with maximum score\n",
        "print(class_labels[pred[0]])"
      ],
      "metadata": {
        "id": "wLbGcf6sxrAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.pridict(\"/content/drive/MyDrive/care buddy/archive/Alzheimer_s Dataset/train/MildDemented/mildDem0.jpg\")"
      ],
      "metadata": {
        "id": "XKLsuUG0wpff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_JL61v4rfvp"
      },
      "outputs": [],
      "source": [
        "train_datagen.class_indices\n",
        "from keras.preprocessing import image\n",
        "path=\"/content/drive/MyDrive/care buddy/archive/Alzheimer_s Dataset/train/MildDemented/mildDem0.jpg\"\n",
        "img=image.load_img(path,target_size=(176,176))\n",
        "img=image.img_to_array(img)/255\n",
        "\n",
        "img=np.array([img])\n",
        "\n",
        "img.shape\n",
        "(model.predict(img) > 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyAsgMXh8KaZ"
      },
      "source": [
        "## **5. Plotting the Model Metrics**\n",
        "### i. Plotting training and validation accuracy, loss and learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fgyDPQf8YT-"
      },
      "source": [
        "\n",
        "## 6. Testing the Model on Test Set\n",
        "Testing the model on the validation dataset because a seperate dataset for testing is not available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mf0uqU9XLMR_"
      },
      "outputs": [],
      "source": [
        "test_dataset = '/content/drive/MyDrive/FYP/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTDgCp5aLZCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c315b7b6-7f5d-4715-fb09-85cef83793d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dataset,\n",
        "                                                 shuffle=False,\n",
        "                                                 batch_size=BATCH_SIZE,\n",
        "                                                 target_size = (IMG_WIDTH, IMG_HEIGHT),\n",
        "                                                 class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX6w-BXS8lIl"
      },
      "source": [
        "## 7. Model Prediction on the Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14IfVL5yLb8V"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q47bAleNrh3W"
      },
      "outputs": [],
      "source": [
        "labels = {value: key for key, value in train_generator.class_indices.items()}\n",
        "\n",
        "print(\"Label Mappings for classes present in the training and validation datasets\\n\")\n",
        "for key, value in labels.items():\n",
        "    print(f\"{key} : {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoluG9CyLf2D"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(12, 10))\n",
        "idx = 0\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(5):\n",
        "        predicted_label = labels [np.argmax(predictions[idx])]\n",
        "        ax [i, j].set_title(f\"{predicted_label}\")\n",
        "        ax [i, j].imshow(test_generator[0][0][idx])\n",
        "        ax[i, j].axis(\"off\")\n",
        "        idx += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Test Dataset Predictions\", fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7nNgwHjtpm6"
      },
      "outputs": [],
      "source": [
        "train_loss, train_accuracy, train_precision, train_recall, train_auc, train_F1_Score = model.evaluate(train_generator, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8tuKgHTtpqO"
      },
      "outputs": [],
      "source": [
        "print(f\"Train Loss:     {train_loss}\")\n",
        "print(f\"Train Accuracy: {train_accuracy}\")\n",
        "print(f\"Train Precision: {train_precision}\")\n",
        "print(f\"Train Recall: {train_recall}\")\n",
        "print(f\"Train AUC: {train_auc}\")\n",
        "print(f\"Train F1_Score: {np.mean(train_F1_Score)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sc7v2ATMLjHM"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy, test_precision, test_recall, test_auc, test_F1_Score = model.evaluate(test_generator, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPrzCdU7Lm72"
      },
      "outputs": [],
      "source": [
        "print(f\"Test Loss:     {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "print(f\"Test Precision: {test_precision}\")\n",
        "print(f\"Test Recall: {test_recall}\")\n",
        "print(f\"Test AUC: {test_auc}\")\n",
        "print(f\"Test F1_Score: {np.mean(test_F1_Score)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3OTJ31P8xNn"
      },
      "source": [
        "## **8. Plotting the Classification Metrics**\n",
        "### i. Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRr-fy7wLpPA"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = test_generator.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkH1WCGjLt3H"
      },
      "outputs": [],
      "source": [
        "cf_mtx = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "group_counts = [\"{0:0.0f}\".format(value) for value in cf_mtx.flatten()]\n",
        "group_percentages = [\"{0:.2%}\".format(value) for value in cf_mtx.flatten()/np.sum(cf_mtx)]\n",
        "box_labels = [f\"{v1}\\n({v2})\" for v1, v2 in zip(group_counts, group_percentages)]\n",
        "box_labels = np.asarray(box_labels).reshape(4, 4)\n",
        "\n",
        "plt.figure(figsize = (12, 10))\n",
        "sns.heatmap(cf_mtx, xticklabels=labels.values(), yticklabels=labels.values(),\n",
        "           cmap=\"YlGnBu\", fmt=\"\", annot=box_labels)\n",
        "plt.xlabel('Predicted Classes')\n",
        "plt.ylabel('True Classes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRFxSxuoLx7a"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_true, y_pred, target_names=labels.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IbhB94i88Nh"
      },
      "source": [
        "## **9. Wrong Predictions**\n",
        "Let's see where the model has given wrong predictions and what were the actual predictions on those images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAlHgY2fL1qv"
      },
      "outputs": [],
      "source": [
        "errors = (y_true - y_pred != 0)\n",
        "y_true_errors = y_true[errors]\n",
        "y_pred_errors = y_pred[errors]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Taif9J5L57y"
      },
      "outputs": [],
      "source": [
        "test_images = test_generator.filenames\n",
        "test_img = np.asarray(test_images)[errors]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXDgMIoBL8WP"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(12, 10))\n",
        "idx = 0\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(5):\n",
        "        idx = np.random.randint(0, len(test_img))\n",
        "        true_index = y_true_errors[idx]\n",
        "        true_label = labels[true_index]\n",
        "        predicted_index = y_pred_errors[idx]\n",
        "        predicted_label = labels[predicted_index]\n",
        "        ax[i, j].set_title(f\"True Label: {true_label} \\n Predicted Label: {predicted_label}\")\n",
        "        img_path = os.path.join(test_dataset, test_img[idx])\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        ax[i, j].imshow(img)\n",
        "        ax[i, j].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Wrong Predictions made on test set', fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLM-MAi_9zIP"
      },
      "outputs": [],
      "source": [
        "model.save"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}